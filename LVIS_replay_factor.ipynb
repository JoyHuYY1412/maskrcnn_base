{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import time\n",
    "import multiprocessing\n",
    "import copy\n",
    "import os.path as osp\n",
    "# from utils import IdGenerator, id2rgb\n",
    "import pdb\n",
    "import torch\n",
    "try:\n",
    "    import PIL.Image     as Image\n",
    "except:\n",
    "    print(\"Failed to import the image processing packages.\")\n",
    "    sys.exit(-1)\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "# import skimage.io as io\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage ='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_gt_json_file = \"/mnt/data-disk2/xinting/project/dataset/LVIS/lvis_v0.5_\"+stage+\".json\"\n",
    "data_path = './dataset/LVIS/images/'+stage+'2017'\n",
    "with open(inst_gt_json_file, 'r') as f:\n",
    "    inst_gt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "min_keypoints_per_image = 10\n",
    "\n",
    "\n",
    "def _count_visible_keypoints(anno):\n",
    "    return sum(sum(1 for v in ann[\"keypoints\"][2::3] if v > 0) for ann in anno)\n",
    "\n",
    "\n",
    "def _has_only_empty_bbox(anno):\n",
    "    return all(any(o <= 1 for o in obj[\"bbox\"][2:]) for obj in anno)\n",
    "\n",
    "\n",
    "def has_valid_annotation(anno):\n",
    "    # if it's empty, there is no annotation\n",
    "    if len(anno) == 0:\n",
    "        return False\n",
    "    # if all boxes have close to zero area, there is no annotation\n",
    "    if _has_only_empty_bbox(anno):\n",
    "        return False\n",
    "    # keypoints task have a slight different critera for considering\n",
    "    # if an annotation is valid\n",
    "    if \"keypoints\" not in anno[0]:\n",
    "        return True\n",
    "    # for keypoint detection tasks, only consider valid images those\n",
    "    # containing at least min_keypoints_per_image\n",
    "    if _count_visible_keypoints(anno) >= min_keypoints_per_image:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "class COCODataset(torchvision.datasets.coco.CocoDetection):\n",
    "    def __init__(self, root, ann_file, sorted_id, remove_images_without_annotations=False):\n",
    "        super(COCODataset, self).__init__(root, ann_file)\n",
    "        self.ids = sorted(self.ids)\n",
    "\n",
    "        # filter images without detection annotations\n",
    "        if remove_images_without_annotations:\n",
    "            ids = []\n",
    "            for img_id in self.ids:\n",
    "                ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds = sorted_id,iscrowd=None)\n",
    "#                 ann_ids = self.coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "\n",
    "                anno = self.coco.loadAnns(ann_ids)\n",
    "                if has_valid_annotation(anno):\n",
    "                    ids.append(img_id)\n",
    "            self.ids = ids\n",
    "\n",
    "        self.categories = {cat['id']: cat['name'] for cat in self.coco.cats.values()}\n",
    "\n",
    "        self.category_id_to_sorted_id = {\n",
    "            v: i + 1 for i, v in enumerate(sorted_id)\n",
    "        }\n",
    "        self.sorted_id_to_category_id = {\n",
    "            v: k for k, v in self.category_id_to_sorted_id.items()\n",
    "        }\n",
    "        self.id_to_img_map = {k: v for k, v in enumerate(self.ids)}\n",
    "        self.img_map_to_id = {v: k for k, v in self.id_to_img_map.items()}\n",
    "\n",
    "#         self._transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img, anno = super(COCODataset, self).__getitem__(idx)\n",
    "#         print(anno)\n",
    "        return img, anno, idx\n",
    "    \n",
    "    def get_img_info(self, index):\n",
    "        img_id = self.id_to_img_map[index]\n",
    "        img_data = self.coco.imgs[img_id]\n",
    "        return img_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_inst = sorted(inst_gt['categories'], key=lambda k: k['instance_count'], reverse=True) \n",
    "sorted_instance_count = [item['instance_count'] for item in sorted_inst]\n",
    "sorted_class_name = [item['name'] for item in sorted_inst]\n",
    "sorted_frequency = [item['frequency'] for item in sorted_inst]\n",
    "sorted_img_count = [item['image_count'] for item in sorted_inst]\n",
    "sorted_id=[]\n",
    "for i in sorted_inst:\n",
    "    sorted_id.append(i['id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = COCODataset(data_path, inst_gt_json_file, sorted_id, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000\r"
     ]
    }
   ],
   "source": [
    "import sys, math\n",
    "repeat_thresh = 0.001\n",
    "num_images = len(coco_train)\n",
    "# 1. For each category c, compute the fraction of images that contain it: f(c)\n",
    "category_freq = {}\n",
    "for cls, num_img in enumerate(sorted_img_count):\n",
    "    category_freq[cls+1] = num_img\n",
    "for k, v in category_freq.items():\n",
    "    category_freq[k] = v / num_images\n",
    "# 2. For each category c, compute the category-level repeat factor:\n",
    "#    r(c) = max(1, sqrt(t / f(c)))\n",
    "category_rep = {\n",
    "    int(cat_id): max(1.0, math.sqrt(repeat_thresh / cat_freq))\n",
    "    for cat_id, cat_freq in category_freq.items()\n",
    "}\n",
    "# 3. For each image I, compute the image-level repeat factor:\n",
    "#    r(I) = max_{c in I} r(c)\n",
    "rep_factors = []\n",
    "i = 0\n",
    "for img in range(num_images):\n",
    "    i +=1\n",
    "    percent = 1.0 * i / num_images\n",
    "    sys.stdout.write(\"%.4f\"%percent)\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    sys.stdout.flush()\n",
    "    cat_ids = {int(coco_train.category_id_to_sorted_id[ann['category_id']]) for ann in coco_train[img][1]}\n",
    "#     print(cat_ids)\n",
    "    rep_factor = max({category_rep[cat_id] for cat_id in cat_ids})\n",
    "    rep_factors.append(rep_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/mnt/data-disk2/xinting/project/dataset/LVIS/lvis_trainval_1230/lvis_trainval_1230_repeat_factor.npy'\n",
    "np.save(save_path, rep_factors)\n",
    "\n",
    "read_data = np.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64858.1885206132"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskrcnn_benchmark",
   "language": "python",
   "name": "maskrcnn_benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
