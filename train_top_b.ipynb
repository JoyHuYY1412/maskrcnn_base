{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import time\n",
    "import multiprocessing\n",
    "import copy\n",
    "import os.path as osp\n",
    "# from utils import IdGenerator, id2rgb\n",
    "import pdb\n",
    "import torch\n",
    "try:\n",
    "    import PIL.Image     as Image\n",
    "except:\n",
    "    print(\"Failed to import the image processing packages.\")\n",
    "    sys.exit(-1)\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "# import skimage.io as io\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage='val'\n",
    "b = 110\n",
    "step = 160\n",
    "save_path = './datasets/lvis/lvis_trainval_1230'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_gt_json_file = \"./datasets/lvis/lvis_v0.5_\"+stage+\".json\"\n",
    "data_path = './datasets/lvis/images/'+stage+'2017'\n",
    "with open(inst_gt_json_file, 'r') as f:\n",
    "    inst_gt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cls_id_file = os.path.join(save_path, 'lvis_sorted_id_all.json')\n",
    "with open(sorted_cls_id_file, 'r') as f:\n",
    "    sorted_cls_id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_class_ids_top_b = sorted_cls_id[:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(sorted_class_ids_top_b, open(os.path.join(save_path, 'lvis_sorted_id_top'+str(b)+'.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.78s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "min_keypoints_per_image = 10\n",
    "\n",
    "\n",
    "def _count_visible_keypoints(anno):\n",
    "    return sum(sum(1 for v in ann[\"keypoints\"][2::3] if v > 0) for ann in anno)\n",
    "\n",
    "\n",
    "def _has_only_empty_bbox(anno):\n",
    "    return all(any(o <= 1 for o in obj[\"bbox\"][2:]) for obj in anno)\n",
    "\n",
    "\n",
    "def has_valid_annotation(anno):\n",
    "    # if it's empty, there is no annotation\n",
    "    if len(anno) == 0:\n",
    "        return False\n",
    "    # if all boxes have close to zero area, there is no annotation\n",
    "    if _has_only_empty_bbox(anno):\n",
    "        return False\n",
    "    # keypoints task have a slight different critera for considering\n",
    "    # if an annotation is valid\n",
    "    if \"keypoints\" not in anno[0]:\n",
    "        return True\n",
    "    # for keypoint detection tasks, only consider valid images those\n",
    "    # containing at least min_keypoints_per_image\n",
    "    if _count_visible_keypoints(anno) >= min_keypoints_per_image:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "class COCODataset(torchvision.datasets.coco.CocoDetection):\n",
    "    def __init__(self, root, ann_file, remove_images_without_annotations=False):\n",
    "        super(COCODataset, self).__init__(root, ann_file)\n",
    "        self.ids = sorted(self.ids)\n",
    "\n",
    "        # filter images without detection annotations\n",
    "        if remove_images_without_annotations:\n",
    "            ids = []\n",
    "            for img_id in self.ids:\n",
    "#                 ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds = id_gt,iscrowd=None)\n",
    "                ann_ids = self.coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "\n",
    "                anno = self.coco.loadAnns(ann_ids)\n",
    "                if has_valid_annotation(anno):\n",
    "                    ids.append(img_id)\n",
    "            self.ids = ids\n",
    "\n",
    "        self.categories = {cat['id']: cat['name'] for cat in self.coco.cats.values()}\n",
    "\n",
    "#         self.json_category_id_to_contiguous_id = {\n",
    "#             v: i + 1 for i, v in enumerate(self.coco.getCatIds())\n",
    "#         }\n",
    "#         self.contiguous_category_id_to_json_id = {\n",
    "#             v: k for k, v in self.json_category_id_to_contiguous_id.items()\n",
    "#         }\n",
    "        self.id_to_img_map = {k: v for k, v in enumerate(self.ids)}\n",
    "#         self._transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img, anno = super(COCODataset, self).__getitem__(idx)\n",
    "        return img, anno\n",
    "    \n",
    "    def get_img_info(self, index):\n",
    "        img_id = self.id_to_img_map[index]\n",
    "        img_data = self.coco.imgs[img_id]\n",
    "        return img_data\n",
    "    \n",
    "coco = COCODataset(data_path,inst_gt_json_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建只有108类所有标注的小数据集\n",
    "inst_gt_subset = inst_gt.copy()\n",
    "annotations_subset = []\n",
    "\n",
    "for class_i in sorted_class_ids_top_b:\n",
    "    ann_list = coco.coco.getAnnIds(catIds=class_i)\n",
    "    annotations_subset.extend(coco.coco.loadAnns(ids=ann_list))\n",
    "inst_gt_subset['annotations'] = annotations_subset\n",
    "\n",
    "json.dump(inst_gt_subset, open(os.path.join(save_path, 'lvis_v0.5_'+stage+'_top'+str(b)+'.json'), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stage == 'val':\n",
    "    for i in inst_gt_subset['categories']:\n",
    "        if i['id'] in sorted_cls_id[:b]:\n",
    "            i['step_state'] = 'b0'\n",
    "       elif i['id'] in sorted_cls_id[b:270+160]:\n",
    "            i['step_state'] = 't0'\n",
    "       else:\n",
    "            i['step_state'] = 't1'\n",
    "    json.dump(inst_gt_subset, open(os.path.join(save_path, 'lvis_v0.5_'+stage+'_top'+str(b)+'.json'), 'w'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskrcnn_benchmark",
   "language": "python",
   "name": "maskrcnn_benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
