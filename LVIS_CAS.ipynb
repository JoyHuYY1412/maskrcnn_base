{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import time\n",
    "import multiprocessing\n",
    "import copy\n",
    "import os.path as osp\n",
    "# from utils import IdGenerator, id2rgb\n",
    "import pdb\n",
    "import torch\n",
    "try:\n",
    "    import PIL.Image     as Image\n",
    "except:\n",
    "    print(\"Failed to import the image processing packages.\")\n",
    "    sys.exit(-1)\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "# import skimage.io as io\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage ='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_gt_json_file = \"/mnt/data-disk2/xinting/project/dataset/LVIS/lvis_v0.5_\"+stage+\".json\"\n",
    "data_path = './dataset/LVIS/images/'+stage+'2017'\n",
    "with open(inst_gt_json_file, 'r') as f:\n",
    "    inst_gt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "min_keypoints_per_image = 10\n",
    "\n",
    "\n",
    "def _count_visible_keypoints(anno):\n",
    "    return sum(sum(1 for v in ann[\"keypoints\"][2::3] if v > 0) for ann in anno)\n",
    "\n",
    "\n",
    "def _has_only_empty_bbox(anno):\n",
    "    return all(any(o <= 1 for o in obj[\"bbox\"][2:]) for obj in anno)\n",
    "\n",
    "\n",
    "def has_valid_annotation(anno):\n",
    "    # if it's empty, there is no annotation\n",
    "    if len(anno) == 0:\n",
    "        return False\n",
    "    # if all boxes have close to zero area, there is no annotation\n",
    "    if _has_only_empty_bbox(anno):\n",
    "        return False\n",
    "    # keypoints task have a slight different critera for considering\n",
    "    # if an annotation is valid\n",
    "    if \"keypoints\" not in anno[0]:\n",
    "        return True\n",
    "    # for keypoint detection tasks, only consider valid images those\n",
    "    # containing at least min_keypoints_per_image\n",
    "    if _count_visible_keypoints(anno) >= min_keypoints_per_image:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "class COCODataset(torchvision.datasets.coco.CocoDetection):\n",
    "    def __init__(self, root, ann_file, sorted_id, remove_images_without_annotations=False):\n",
    "        super(COCODataset, self).__init__(root, ann_file)\n",
    "        self.ids = sorted(self.ids)\n",
    "\n",
    "        # filter images without detection annotations\n",
    "        if remove_images_without_annotations:\n",
    "            ids = []\n",
    "            for img_id in self.ids:\n",
    "                ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds = sorted_id,iscrowd=None)\n",
    "#                 ann_ids = self.coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "\n",
    "                anno = self.coco.loadAnns(ann_ids)\n",
    "                if has_valid_annotation(anno):\n",
    "                    ids.append(img_id)\n",
    "            self.ids = ids\n",
    "\n",
    "        self.categories = {cat['id']: cat['name'] for cat in self.coco.cats.values()}\n",
    "\n",
    "        self.category_id_to_sorted_id = {\n",
    "            v: i + 1 for i, v in enumerate(sorted_id)\n",
    "        }\n",
    "        self.sorted_id_to_category_id = {\n",
    "            v: k for k, v in self.category_id_to_sorted_id.items()\n",
    "        }\n",
    "        self.id_to_img_map = {k: v for k, v in enumerate(self.ids)}\n",
    "        self.img_map_to_id = {v: k for k, v in self.id_to_img_map.items()}\n",
    "\n",
    "#         self._transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img, anno = super(COCODataset, self).__getitem__(idx)\n",
    "#         print(anno)\n",
    "        return img, anno, idx\n",
    "    \n",
    "    def get_img_info(self, index):\n",
    "        img_id = self.id_to_img_map[index]\n",
    "        img_data = self.coco.imgs[img_id]\n",
    "        return img_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_inst = sorted(inst_gt['categories'], key=lambda k: k['instance_count'], reverse=True) \n",
    "sorted_instance_count = [item['instance_count'] for item in sorted_inst]\n",
    "sorted_class_name = [item['name'] for item in sorted_inst]\n",
    "sorted_frequency = [item['frequency'] for item in sorted_inst]\n",
    "sorted_img_count = [item['image_count'] for item in sorted_inst]\n",
    "sorted_id=[]\n",
    "for i in sorted_inst:\n",
    "    sorted_id.append(i['id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=21.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = COCODataset(data_path, inst_gt_json_file, sorted_id, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class RandomCycleIter:\n",
    "    \"\"\"\n",
    "    Randomly iterate element in each cycle\n",
    "    Example:\n",
    "      >>> rand_cyc_iter = RandomCycleIter([1, 2, 3])\n",
    "      >>> [next(rand_cyc_iter) for _ in range(10)]\n",
    "      [2, 1, 3, 2, 3, 1, 1, 2, 3, 2]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data_list = list(data)\n",
    "        self.length = len(self.data_list)\n",
    "        self.i = self.length - 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self.i += 1\n",
    "        if self.i == self.length:\n",
    "            self.i = 0\n",
    "            random.shuffle(self.data_list)\n",
    "        return self.data_list[self.i]\n",
    "\n",
    "    next = __next__  # Py2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cls = 1230\n",
    "class_iter = RandomCycleIter(range(n_cls))\n",
    "cls_data_list = [list() for _ in range(n_cls)]\n",
    "# cls_data_list = [['a','b'],['cc','dd'],['eee','fff','ggg']]\n",
    "for img in range(len(coco_train)):\n",
    "    cat_ids = {int(coco_train.category_id_to_sorted_id[ann['category_id']]) for ann in coco_train[img][1]}\n",
    "    for cat_id in cat_ids:\n",
    "        cls_data_list[cat_id-1].append(img)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_GPU = 8\n",
    "num_iter = 80000        \n",
    "indices = [list() for _ in range(n_GPU)]\n",
    "data_iter_list_all = [list() for _ in range(n_cls)]\n",
    "for rank in range(n_GPU):\n",
    "    data_iter_list = [RandomCycleIter(cls_data) for cls_data in cls_data_list]\n",
    "    for cls in range(n_cls):\n",
    "        data_iter_list_all[cls].extend([next(data_iter_list[cls]) for _ in range(num_iter)])\n",
    "    iter_id_stage = [0]*n_cls\n",
    "    for iter_id in [next(class_iter) for _ in range(num_iter)]:\n",
    "        indices[rank].append(data_iter_list_all[iter_id][iter_id_stage[iter_id]])\n",
    "        iter_id_stage[iter_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/mnt/data-disk2/xinting/project/dataset/LVIS/lvis_trainval_1230/lvis_trainval_1230_CAS.npy'\n",
    "np.save(save_path, indices)\n",
    "\n",
    "read_indices = np.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64858.1885206132"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34575, 30121, 33959, 48104, 29453, 21836, 9340, 40901, 17018, 16469]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34575, 30121, 33959, 48104, 29453, 21836, 9340, 40901, 17018, 16469]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_indices.tolist()[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34575, 30121, 33959, 48104, 29453, 21836,  9340, 40901, 17018,\n",
       "       16469])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskrcnn_benchmark",
   "language": "python",
   "name": "maskrcnn_benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
